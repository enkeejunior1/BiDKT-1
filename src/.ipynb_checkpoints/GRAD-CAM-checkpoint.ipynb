{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70df24bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0a8ce2",
   "metadata": {},
   "source": [
    "# monacoBERT + Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8926d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationsAndGradients:\n",
    "    \"\"\" Class for extracting activations and\n",
    "    registering gradients from targetted intermediate layers \n",
    "    \n",
    "    ref : https://github.com/jacobgil/pytorch-grad-cam/blob/a701308935d7bc18ec0659eddc95fd6d3e315fd2/pytorch_grad_cam/activations_and_gradients.py#L1\n",
    "    \"\"\"\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.gradients = []\n",
    "        self.activations = []\n",
    "        self.handles = []\n",
    "        for target_layer in target_layers:\n",
    "            self.handles.append(\n",
    "                target_layer.register_forward_hook(self.save_activation))\n",
    "            # Because of https://github.com/pytorch/pytorch/issues/61519,\n",
    "            # we don't use backward hook to record gradients.\n",
    "            self.handles.append(\n",
    "                target_layer.register_forward_hook(self.save_gradient))\n",
    "\n",
    "    def save_activation(self, module, input, output):\n",
    "        activation = output\n",
    "        self.activations.append(activation.cpu().detach())\n",
    "\n",
    "    def save_gradient(self, module, input, output):\n",
    "        if not hasattr(output, \"requires_grad\") or not output.requires_grad:\n",
    "            # You can only register hooks on tensor requires grad.\n",
    "            return\n",
    "\n",
    "        # Gradients are computed in reverse order\n",
    "        def _store_grad(grad):\n",
    "            self.gradients = [grad.cpu().detach()] + self.gradients\n",
    "\n",
    "        output.register_hook(_store_grad)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.gradients = []\n",
    "        self.activations = []\n",
    "        return self.model(x)\n",
    "\n",
    "    def release(self):\n",
    "        for handle in self.handles:\n",
    "            handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "791cec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# hyperparameters\n",
    "gpu_id = 0 if torch.cuda.is_available() else -1\n",
    "device = torch.device('cuda:1')\n",
    "max_seq_len = 100\n",
    "train_ratio = .8\n",
    "valid_ratio = .1\n",
    "hidden_size = 512\n",
    "output_size = 1\n",
    "num_head = 8\n",
    "num_encoder = 12\n",
    "use_leakyrelu = True\n",
    "dropout_p = .1\n",
    "learning_rate = 0.001\n",
    "grad_acc = True\n",
    "grad_acc_iter = 8\n",
    "\n",
    "batch_size = 128\n",
    "n_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f99f230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "from dataloaders.assist2009_pid_diff_loader import ASSIST2009_PID_DIFF\n",
    "from utils import pid_diff_collate_fn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "dataset = ASSIST2009_PID_DIFF(max_seq_len)\n",
    "num_q = dataset.num_q\n",
    "num_r = dataset.num_r\n",
    "num_pid = dataset.num_pid\n",
    "num_diff = dataset.num_diff\n",
    "collate = pid_diff_collate_fn\n",
    "\n",
    "train_size = int( len(dataset) * train_ratio * (1 - valid_ratio))\n",
    "valid_size = int( len(dataset) * train_ratio * valid_ratio)\n",
    "test_size = len(dataset) - (train_size + valid_size)\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = random_split(\n",
    "    dataset, [ train_size, valid_size, test_size ]\n",
    "    )\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True, # train_loader use shuffle\n",
    "    collate_fn = collate\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False, # valid_loader don't use shuffle\n",
    "    collate_fn = collate\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = False, # test_loader don't use shuffle\n",
    "    collate_fn = collate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29b3ed55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from models.visualizer_monacobert_gradcam import MonaConvBert4ktPlusDiffGradCAM\n",
    "\n",
    "model = MonaConvBert4ktPlusDiffGradCAM(\n",
    "    num_q=num_q,\n",
    "    num_r=num_r,\n",
    "    num_pid=num_pid,\n",
    "    num_diff=num_diff,\n",
    "    hidden_size=hidden_size,\n",
    "    output_size=output_size,\n",
    "    num_head=16, # TODO : 16 인데 실제로는 8 임, head_ratio 확인\n",
    "    num_encoder=num_encoder,\n",
    "    max_seq_len=max_seq_len,\n",
    "    device=device,\n",
    "    use_leakyrelu=use_leakyrelu,\n",
    "    dropout_p=dropout_p\n",
    ").to(device)\n",
    "\n",
    "model_path = '/root/BiDKT/model_records/assist09.pth'\n",
    "model_dict = torch.load(model_path)\n",
    "model.load_state_dict(model_dict['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a537c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layers = []\n",
    "for encoder in model.encoder:\n",
    "    target_layers.extend([encoder.attn.attn_hook_helper, \n",
    "                          encoder.attn.conv_hook_helper])\n",
    "    \n",
    "grad_attn_layers = {}\n",
    "grad_conv_layers = {}\n",
    "for layer_idx in range(num_encoder):\n",
    "    for head_idx in range(num_head):\n",
    "        grad_attn_layers[f'{layer_idx}-{head_idx}'] = []\n",
    "        grad_conv_layers[f'{layer_idx}-{head_idx}'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f421fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_and_grad = ActivationsAndGradients(\n",
    "    model = model, \n",
    "    target_layers = target_layers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42f5f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import binary_cross_entropy\n",
    "crit = binary_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e0738ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mlm4BertTest(r_seqs, mask_seqs):\n",
    "    #|r_seqs| = (bs, n)\n",
    "\n",
    "    mlm_r_seqs = []\n",
    "    mlm_idxs = []\n",
    "\n",
    "    for r_seq, mask_seq in zip(r_seqs, mask_seqs):\n",
    "        r_len = r_seq.size(0)\n",
    "\n",
    "        real_r_seq = torch.masked_select(r_seq, mask_seq).cpu()\n",
    "        real_r_seq_len = real_r_seq.size(0)\n",
    "\n",
    "        # last index of real_r_seq\n",
    "        mlm_idx = real_r_seq_len - 1\n",
    "        # last index get a <MASK>, <MASK> is 2\n",
    "        real_r_seq[mlm_idx] = 2\n",
    "\n",
    "        pad_len = r_len - real_r_seq_len\n",
    "        pad_seq = torch.full((1, pad_len), 3).squeeze(0) # <PAD> is 3\n",
    "        pad_r_seq = torch.cat((real_r_seq, pad_seq), dim=-1)\n",
    "        mlm_r_seqs.append(pad_r_seq)\n",
    "\n",
    "        mlm_zeros = np.zeros(shape=(r_len, ))\n",
    "        mlm_zeros[mlm_idx] = 1\n",
    "        mlm_idxs.append(mlm_zeros)\n",
    "\n",
    "    mlm_r_seqs = torch.stack(mlm_r_seqs)\n",
    "    mlm_idxs = torch.BoolTensor(mlm_idxs)\n",
    "\n",
    "    return mlm_r_seqs, mlm_idxs\n",
    "    # |mlm_r_seqs| = (bs, n)\n",
    "    # |mask_seqs| = (bs, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f0f901f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:210.)\n",
      "9it [00:07,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model.eval()\n",
    "for batch_idx, data in tqdm(enumerate(test_loader)):\n",
    "    q_seqs, r_seqs, pid_seqs, diff_seqs, mask_seqs = data\n",
    "\n",
    "    q_seqs = q_seqs.to(device)\n",
    "    r_seqs = r_seqs.to(device)\n",
    "    pid_seqs = pid_seqs.to(device)\n",
    "    diff_seqs = diff_seqs.to(device)\n",
    "    mask_seqs = mask_seqs.to(device)\n",
    "\n",
    "    real_seqs = r_seqs.clone()\n",
    "\n",
    "    mlm_r_seqs, mlm_idxs = Mlm4BertTest(r_seqs, mask_seqs)\n",
    "\n",
    "    mlm_r_seqs = mlm_r_seqs.to(device)\n",
    "    mlm_idxs = mlm_idxs.to(device)\n",
    "\n",
    "    y_hat = model(\n",
    "        q_seqs.long(),\n",
    "        mlm_r_seqs.long(),\n",
    "        pid_seqs.long(),\n",
    "        diff_seqs.long(),\n",
    "        mask_seqs.long()\n",
    "    )\n",
    "\n",
    "    y_hat = y_hat.squeeze()\n",
    "\n",
    "    y_hat = torch.masked_select(y_hat, mlm_idxs)\n",
    "    correct = torch.masked_select(real_seqs, mlm_idxs)\n",
    "\n",
    "    loss = crit(y_hat, correct)\n",
    "    loss.backward()\n",
    "    \n",
    "#     for grad in act_and_grad.gradients:\n",
    "#         print(grad.shape)\n",
    "    \n",
    "#     act_and_grad.gradients = []\n",
    "#     act_and_grad.activations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae5778",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "relu = nn.ReLU()\n",
    "\n",
    "def _batch_to_sample(data):\n",
    "    batch = [torch.stack([\n",
    "        q_seqs.type(torch.long), \n",
    "        r_seqs.type(torch.long), \n",
    "        pid_seqs.type(torch.long), \n",
    "        diff_seqs.type(torch.long), \n",
    "        mask_seqs.type(torch.long)], dim = 1) for q_seqs, r_seqs, pid_seqs, diff_seqs, mask_seqs in zip(*data)]\n",
    "    return batch\n",
    "\n",
    "for batch_idx, data in tqdm(enumerate(test_loader)):\n",
    "    batch = _batch_to_sample(data)\n",
    "    if len(act_and_grad.gradients[2*batch_idx:2*batch_idx+24]) == 24:\n",
    "        gradients = act_and_grad.gradients[2*batch_idx:2*batch_idx+24]\n",
    "    else:\n",
    "        gradients = act_and_grad.gradients[2*batch_idx:]\n",
    "    \n",
    "    for seq_idx, seq in enumerate(batch):\n",
    "        for sample_idx, sample in enumerate(seq):\n",
    "            q    = int(sample[0])\n",
    "            r    = int(sample[1])\n",
    "            pid  = int(sample[2])\n",
    "            diff = int(sample[3])\n",
    "            is_mask = bool(sample[4])                \n",
    "\n",
    "            if is_mask is True:\n",
    "                for encoder_idx in range(num_encoder):\n",
    "                    for head_idx in range(num_head):\n",
    "                        grad_attn_layers[f'{layer_idx}-{head_idx}'] += \\\n",
    "                        [relu(gradients[2*encoder_idx])[seq_idx, sample_idx, head_idx, ...]]\n",
    "                        grad_conv_layers[f'{layer_idx}-{head_idx}'] += \\\n",
    "                        [relu(gradients[2*encoder_idx+1][seq_idx, sample_idx, head_idx, ...])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c43aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c36a5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(activation(act_and_grad.gradients[0]).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "da7659e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 8, 32])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_and_grad.gradients[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "23af998d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 8, 32])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_and_grad.activations[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "171b158d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "389ca6d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e84440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_grad_per_sample(batch, act_and_grad, grad_attn_layers, grad_conv_layers):\n",
    "    for seq_idx, seq in enumerate(batch):\n",
    "        for sample_idx, sample in enumerate(seq):\n",
    "            q    = int(sample[0])\n",
    "            r    = int(sample[1])\n",
    "            pid  = int(sample[2])\n",
    "            diff = int(sample[3])\n",
    "            is_mask = bool(sample[4])                \n",
    "\n",
    "            print(activation(act_and_grad.gradients[0]).mean())\n",
    "\n",
    "            if is_mask is True:\n",
    "                for encoder_idx in range(num_encoder):\n",
    "                    for head_idx in range(num_head):\n",
    "                        act_and_grad.gradients[2*encoder_idx][seq_idx][head_idx]\n",
    "                        act_and_grad.gradients[2*encoder_idx+1][seq_idx]\n",
    "                        # save \n",
    "                        grad_attn_layers[]\n",
    "                        grad_attn_layers[f'-{head}']\n",
    "                        grad_conv_layers\n",
    "\n",
    "                        # save filter\n",
    "                        self.filter_dict_q[q][encoder_idx]       += [filter_layers[seq_idx, sample_idx, encoder_idx, ...]]\n",
    "                        self.filter_dict_pid[pid][encoder_idx]   += [filter_layers[seq_idx, sample_idx, encoder_idx, ...]]\n",
    "                        self.filter_dict_diff[diff][encoder_idx] += [filter_layers[seq_idx, sample_idx, encoder_idx, ...]]\n",
    "\n",
    "                        # save conv value vector\n",
    "                        self.conv_value_dict_q[q][encoder_idx]       += [value_layers[seq_idx, sample_idx, encoder_idx, ...]]\n",
    "                        self.conv_value_dict_pid[pid][encoder_idx]   += [value_layers[seq_idx, sample_idx, encoder_idx, ...]]\n",
    "                        self.conv_value_dict_diff[diff][encoder_idx] += [value_layers[seq_idx, sample_idx, encoder_idx, ...]]\n",
    "\n",
    "                        # save attn\n",
    "                        for head_idx in range(model.encoder[0].attn.num_attention_heads):\n",
    "                            self.attn_dict[head_idx][encoder_idx] += [attn_layers[seq_idx, encoder_idx, head_idx, ...]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6524350c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = _split_batch(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abeac600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_blackbox(self, data):\n",
    "    '''save attn, filter, conv_value to self.~\n",
    "    '''\n",
    "\n",
    "    def _hook_blackbox(attn):\n",
    "        '''get attn, filter, conv_value from self.model.encoder.attn\n",
    "        attn_scores : [bs, head_idx, num_seq, num_seq]\n",
    "        conv_values : [bs, num_seq, head_idx, hidden_dim]\n",
    "        conv_filter : [bs, num_seq, head_idx, kernel_size]\n",
    "        '''\n",
    "        attn_scores = attn.attn_scores \n",
    "        conv_values = rearrange(\n",
    "            attn.conv_value_vectors.detach().clone(), \n",
    "            'bs (h_idx h_size) n 1 -> bs n h_idx h_size', h_idx = 8)\n",
    "        conv_filter = rearrange(\n",
    "            attn.filters.detach().clone(), \n",
    "            '(bs n h) k 1 -> bs n h k', n = 100, h = 8)\n",
    "        return {'attn' : attn_scores, 'value' : conv_values, 'filter' : conv_filter}\n",
    "\n",
    "    # organize data, hook to easily get the attr\n",
    "    batch = [torch.stack([q_seqs.type(torch.long), \n",
    "                          r_seqs.type(torch.long), \n",
    "                          pid_seqs.type(torch.long), \n",
    "                          diff_seqs.type(torch.long), \n",
    "                          mask_seqs.type(torch.long)], dim = 1) for q_seqs, r_seqs, pid_seqs, diff_seqs, mask_seqs in zip(*data)]\n",
    "\n",
    "    attn_list = [self.model.encoder[encoder_idx].attn for encoder_idx in range(num_encoder)]\n",
    "    hook_list = list(map(_hook_blackbox, attn_list))\n",
    "\n",
    "    attn_layers = torch.stack([hook['attn'] for hook in hook_list], dim = 1) # [bs, layer_idx, head_idx, num_seq, num_seq]\n",
    "    value_layers = torch.stack([hook['value'] for hook in hook_list], dim = 2) # [bs, num_seq, layer_idx, head_idx, hidden_dim]\n",
    "    filter_layers = torch.stack([hook['filter'] for hook in hook_list], dim = 2) # [bs, num_seq, layer_idx, head_idx, kernel_sizehook_list\n",
    "\n",
    "    # save hook to self.~\n",
    "    for seq_idx, seq in enumerate(batch):\n",
    "        for sample_idx, sample in enumerate(seq):\n",
    "            q    = int(sample[0])\n",
    "            r    = int(sample[1])\n",
    "            pid  = int(sample[2])\n",
    "            diff = int(sample[3])\n",
    "            is_mask = bool(sample[4])                \n",
    "\n",
    "            if is_mask is True:\n",
    "                for encoder_idx in range(num_encoder):\n",
    "                    # save filter\n",
    "                    self.filter_dict_q[q][encoder_idx]       += [filter_layers[seq_idx, sample_idx, encoder_idx, ...]]\n",
    "                    self.filter_dict_pid[pid][encoder_idx]   += [filter_layers[seq_idx, sample_idx, encoder_idx, ...]]\n",
    "                    self.filter_dict_diff[diff][encoder_idx] += [filter_layers[seq_idx, sample_idx, encoder_idx, ...]]\n",
    "\n",
    "                    # save conv value vector\n",
    "                    self.conv_value_dict_q[q][encoder_idx]       += [value_layers[seq_idx, sample_idx, encoder_idx, ...]]\n",
    "                    self.conv_value_dict_pid[pid][encoder_idx]   += [value_layers[seq_idx, sample_idx, encoder_idx, ...]]\n",
    "                    self.conv_value_dict_diff[diff][encoder_idx] += [value_layers[seq_idx, sample_idx, encoder_idx, ...]]\n",
    "\n",
    "                    # save attn\n",
    "                    for head_idx in range(model.encoder[0].attn.num_attention_heads):\n",
    "                        self.attn_dict[head_idx][encoder_idx] += [attn_layers[seq_idx, encoder_idx, head_idx, ...]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e87c4d4",
   "metadata": {},
   "source": [
    "# MNIST + simple CNN example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "82d2ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14fc33bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 2\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef12921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple cnn\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(10, 20, kernel_size=5),\n",
    "            nn.Dropout(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(320, 50),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(50, 10),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        self.hook_helper = HookHelper()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.hook_helper(x)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n",
    "class HookHelper(nn.Module):\n",
    "    '''custom Module wrapper for register_forward_hook\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f1e80522",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('mnist_data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "abfe4745",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "667ae3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5809288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_and_grad = ActivationsAndGradients(\n",
    "    model = cnn, \n",
    "    target_layers = [cnn.conv_layers[2], cnn.conv_layers[6], cnn.hook_helper]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8e7243f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = act_and_grad(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9b20782",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationsAndGradients:\n",
    "    \"\"\" Class for extracting activations and\n",
    "    registering gradients from targetted intermediate layers \"\"\"\n",
    "\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.gradients = []\n",
    "        self.activations = []\n",
    "        self.handles = []\n",
    "        for target_layer in target_layers:\n",
    "            self.handles.append(\n",
    "                target_layer.register_forward_hook(self.save_activation))\n",
    "            # Because of https://github.com/pytorch/pytorch/issues/61519,\n",
    "            # we don't use backward hook to record gradients.\n",
    "            self.handles.append(\n",
    "                target_layer.register_forward_hook(self.save_gradient))\n",
    "\n",
    "    def save_activation(self, module, input, output):\n",
    "        activation = output\n",
    "        self.activations.append(activation.cpu().detach())\n",
    "\n",
    "    def save_gradient(self, module, input, output):\n",
    "        if not hasattr(output, \"requires_grad\") or not output.requires_grad:\n",
    "            # You can only register hooks on tensor requires grad.\n",
    "            return\n",
    "\n",
    "        # Gradients are computed in reverse order\n",
    "        def _store_grad(grad):\n",
    "            self.gradients = [grad.cpu().detach()] + self.gradients\n",
    "\n",
    "        output.register_hook(_store_grad)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.gradients = []\n",
    "        self.activations = []\n",
    "        return self.model(x)\n",
    "\n",
    "    def release(self):\n",
    "        for handle in self.handles:\n",
    "            handle.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd1d2eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_activation(module, input, output):\n",
    "    global activations\n",
    "    activation = output\n",
    "    activations.append(activation.cpu().detach())\n",
    "\n",
    "def save_gradient(module, input, output):\n",
    "    if not hasattr(output, \"requires_grad\") or not output.requires_grad:\n",
    "        # You can only register hooks on tensor requires grad.\n",
    "        return\n",
    "\n",
    "    # Gradients are computed in reverse order\n",
    "    def _store_grad(grad):\n",
    "        gradients = [grad.cpu().detach()] + gradients\n",
    "\n",
    "    output.register_hook(_store_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a509fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "## instance input\n",
    "model = cnn\n",
    "target_layers = [cnn.conv_layers[2], cnn.conv_layers[6]]\n",
    "\n",
    "## init\n",
    "gradients = []\n",
    "activations = []\n",
    "handles = []\n",
    "for target_layer in target_layers:\n",
    "    handles.append(target_layer.register_forward_hook(save_activation))\n",
    "    handles.append(target_layer.register_forward_hook(save_gradient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac9b06d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "save_activation() missing 1 required positional argument: 'output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-dff181fae6c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-d3fc986ba10e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m                 \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: save_activation() missing 1 required positional argument: 'output'"
     ]
    }
   ],
   "source": [
    "## call\n",
    "cnn(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4503ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __call__(self, x):\n",
    "    self.gradients = []\n",
    "    self.activations = []\n",
    "    return self.model(x)\n",
    "\n",
    "def release(self):\n",
    "    for handle in self.handles:\n",
    "        handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4429c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target_layer in target_layers:\n",
    "            self.handles.append(\n",
    "                target_layer.register_forward_hook(self.save_activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75952ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc57396f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da2e00e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cnn(batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90541e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93c64e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d8fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_and_grads = ActivationsAndGradients(cnn, [cnn.conv_layers[2], cnn.conv_layers[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a4bca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationsAndGradients:\n",
    "    \"\"\" Class for extracting activations and\n",
    "    registering gradients from targetted intermediate layers \"\"\"\n",
    "\n",
    "    def __init__(self, model, target_layers):\n",
    "        self.model = model\n",
    "        self.gradients = []\n",
    "        self.activations = []\n",
    "        self.handles = []\n",
    "        for target_layer in target_layers:\n",
    "            self.handles.append(\n",
    "                target_layer.register_forward_hook(self.save_activation))\n",
    "            # Because of https://github.com/pytorch/pytorch/issues/61519,\n",
    "            # we don't use backward hook to record gradients.\n",
    "            self.handles.append(\n",
    "                target_layer.register_forward_hook(self.save_gradient))\n",
    "\n",
    "    def save_activation(self, module, input, output):\n",
    "        activation = output\n",
    "        self.activations.append(activation.cpu().detach())\n",
    "\n",
    "    def save_gradient(self, module, input, output):\n",
    "        if not hasattr(output, \"requires_grad\") or not output.requires_grad:\n",
    "            # You can only register hooks on tensor requires grad.\n",
    "            return\n",
    "\n",
    "        # Gradients are computed in reverse order\n",
    "        def _store_grad(grad):\n",
    "            self.gradients = [grad.cpu().detach()] + self.gradients\n",
    "\n",
    "        output.register_hook(_store_grad)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.gradients = []\n",
    "        self.activations = []\n",
    "        return self.model(x)\n",
    "\n",
    "    def release(self):\n",
    "        for handle in self.handles:\n",
    "            handle.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38256703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5cb7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward + \n",
    "\n",
    "# GRAD CAM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
